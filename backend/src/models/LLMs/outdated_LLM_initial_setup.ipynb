{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LLM Set Up"
      ],
      "metadata": {
        "id": "ZGPMaobopomM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2AllbTs4tM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b286db9c-7615-400f-b3bb-9048dfef0e83",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.45.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "#API keys shared internally for now, in the future will be built into GitHub for all\n",
        "!pip install anthropic\n",
        "from google.colab import userdata\n",
        "griffin_api_key = userdata.get('Claude_API')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "from anthropic import Anthropic\n",
        "import pandas as pd\n",
        "\n",
        "responses = pd.read_csv(\"dataResponses_cleaned.csv\")\n",
        "responses = responses.responses[50:100]"
      ],
      "metadata": {
        "id": "nI7YQ-O0MZFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = anthropic.Anthropic(\n",
        "    api_key=griffin_api_key,\n",
        ")\n",
        "MODEL_NAME = \"claude-3-opus-20240229\"\n",
        "\n",
        "def get_completion(client, prompt):\n",
        "    return client.messages.create(\n",
        "        model=MODEL_NAME,\n",
        "        max_tokens=2048,\n",
        "        messages=[{\n",
        "            \"role\": 'user', \"content\": prompt\n",
        "        }]\n",
        "    ).content[0].text\n"
      ],
      "metadata": {
        "id": "3bTv3kq24vNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 5\n",
        "all_tags = []\n",
        "example = [\"\"\"Greater availability for online students\taccess to info\n",
        "Easily obtained and accessible information. \taccess to info\n",
        "Easier access to sources or relevant information that is not as easy to find \taccess to info\n",
        "if they work, helping give examples or providing basic info\taccess to info\n",
        "It gives students concise answers that may have gone unanswered otherwise.\taccess to info\n",
        "Learning things in-depth\taccess to info, teaching\n",
        "Help answers students questions about school work \taccess to info, teaching, feedback & study support\n",
        "It is an ultimately helpful tool for educational purposes. You have examples at your fingertips to do possibly anything.\taccess to info, feedback & study support\n",
        "Access to knowledge as a study tool\taccess to info, feeback & study support\n",
        "Access and Availability are two key benefits.   These systems can operate and be accessible around the clock and at any location that is accessible to the web (including a portable smart device)\taccess to info\n",
        "Expansion info\taccess to info\n",
        "Immediate and concise answers.\taccess to info\n",
        "They are a great source to find information\taccess to info\n",
        "access to information to learn about a topic\taccess to info\n",
        "Research opportunities/ Information Hub \taccess to info\n",
        "It can give quick summaries of important topics. \taccess to info\n",
        "Give new information you donâ€™t know\taccess to info\n",
        "Chatbots are great for summarizing material. \taccess to info\n",
        "Providing instant feedback for questions about certain concepts, theorems, or models and possibly referring students to information/websites that have more credibility. \tfeedback & study support\n",
        "I absolutely see benefits and opportunities using AI chatbots in educational settings! You can cater a chat bot to help you acquire more knowledge on a specific topic, in a field you are struggling in.\taccess to info, teaching, feedback & study support\n",
        "Access to resources/info some might have otherwise not have\taccess to info\n",
        "If used correctly, could be a great learning resource. If you ask an AI chatbot for assistance in maybe defining a term then it can be a useful tool. \taccess to info, teaching\n",
        "Information\taccess to info\n",
        "I think AI can be a great help. I personally use it often to ask for formulas in excel that I don't have committed to memory. \taccess to info\n",
        "AI would provide an even broader resource and fountain for information. \taccess to info\n",
        "it can be used as a way to find sources/articles for research discussions\taccess to info\n",
        "It's easier to get the information you need and ask for clarification.\taccess to info, teaching\n",
        "Helping understand key objectives and summarizing topics to help study and learn.\tfeedback & study support\n",
        "It can give you sources to expand your knowledge. It can teach you things you are struggling with.\taccess to info, teaching\n",
        "AI chatbots can be beneficial in their ability to produce useful information about any topic at the drop of a hat and to also be able ti articulate it in a way that is easy to understand.\taccess to info\n",
        "AI chatbots can help people when there stuck or need more information. \taccess to info, teaching, feedback & study support\n",
        "It can help you study way quicker by summarizing, organizing information and better explaining it\tfeedback & study support, teaching\n",
        "Students can use AI to help them learn information which may have been misunderstood in the classroom.\tteaching\n",
        "They can help with questions and ellaborates on problems.\tteaching, feedback & study support\n",
        "maybe to teach really basic information or for menial tasks\tteaching, speeds up work\n",
        "Consise advanced research. Clarification and elaboration.\taccess to info\n",
        "They can be a great source for asking questions in specific topics as long as the user verifies the responses and has a general understanding of what they are doing before referring to the AI chatbot. I find it helpful to work through certain steps in problems that are specific to a topic that I canâ€™t just look up. In higher level courses, it can be difficult to find resources online for such specific problems and tutors/office hours donâ€™t always suffice for the amount of time the support takes. I find AI can be helpful it in explaining why and or how to take certain steps to achieve and answer. Even if it is wrong, it can usually give you some sort of boost towards the correct answer or at least explain the problem well.\tfeedback & study support, starting point\n",
        "AI can explain how to do certain questions, how to approach them, or tell you the general information. It can also give examples which may assist the student in preparing.\tteaching, feedback & study support\n",
        "Benefits include getting an answer about a topic right away, and it can help summarize content you may have trouble understanding.\taccess to info\n",
        "In my experience, AI can be helpful in tracing where to access primary sources, as well as helping understand a difficult phrase by pasting it into the chatbot and asking it to explain it more clearly. It could be used as a tool to double check grammar, but the student should check it afterwards and not assume that the chatbot is correct. Additionally as an educator AI is useful in writing an assignment description or ordering a lesson plan, as a teacher may want to spend more of their time focused on the students.\taccess to info, teaching, feedback & study support, speeds up work\n",
        "AI chatbots can be good to get ideas or find quick information, and they can explain complex/confusing concepts which can assist in the learning process. They can also help people proofread their work and get ideas for writing. Furthermore, AI chatbots can also help people create plans and schedules, helping them better manage their time and resources.\tstarting point, access to info, teaching, feedback & study support, speeds up work\n",
        "Students can further research and learn from AI. \taccess to info, teaching\n",
        "Foreign language practice, example problems for studying\tfeedback & study support\n",
        "One benefit to AI chatbots is that students will be able to gather information about new topics in a very brief overview which will allow them to prepare for class much more easily. Additionally, students may use chatbots to help create practice problems in order to assist them in reviewing for quizzes or exams.\taccess to info, feedback & study support\n",
        "Chatbots can be used as a fast and somewhat reliable method of gaining a summary or can be used as a method for studying \taccess to info, feedback & study support\n",
        "Increased learning via easier access to information, personalized responses to specific questions that are hard to find in places like Google\taccess to info, teaching\n",
        "fast access to wide variety of data and information. customized explanation of complex topics.\taccess to info, teaching\n",
        "Personalized studying improvements, more direct access to information to help education be more efficient\taccess to info, teaching\n",
        "One major benefit is getting information quickly and easily\taccess to info, speeds up work\"\"\"]\n",
        "\n",
        "for i in range(0, len(responses), chunk_size):\n",
        "    chunk = responses[i:i+chunk_size]\n",
        "\n",
        "    prompt = f\"\"\"Look at these responses and provide thematic tags for each one. Take example from these previous tags, you should you these tags unless you would like to add another theme {example}\n",
        "    Format your response as a list where each line has the response number followed by tags, separated by commas.\n",
        "\n",
        "    Responses:\n",
        "    {chunk.to_list()}\n",
        "    \"\"\"\n",
        "\n",
        "    completion = get_completion(client, prompt)\n",
        "    all_tags.extend(completion.split('\\n'))\n",
        "    print(f\"Processed responses {i} to {i+len(chunk)}\")\n",
        "    print(all_tags[i:i+len(chunk)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4-VG7M77L3U",
        "outputId": "9618e358-69ce-40c2-deff-4db4b7a14953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed responses 0 to 5\n",
            "['Here are the responses with thematic tags:', '', '1. quick info on thigns when questions are asked access to info, speeds up work', '2. They can provide information quicker than a google search and can be useful in helping to understand concepts. access to info, speeds up work, teaching', '3. Chatbots can help find general trivia/information much faster, and they can give a cursory summary of an article that can speed up the annotation process. access to info, speeds up work']\n",
            "Processed responses 5 to 10\n",
            "['4. It can help get answers faster. access to info, speeds up work', '5. The speed at which information can be accessed. access to info, speeds up work', 'Here are the responses with thematic tags:', '', '1. access to info, speeds up work']\n",
            "Processed responses 10 to 15\n",
            "['2. access to info, speeds up work', '3. access to info, speeds up work, feedback & study support', '4. access to info, speeds up work', '5. access to info, teaching, feedback & study support, starting point', '1. speeds up work, starting point, access to info']\n",
            "Processed responses 15 to 20\n",
            "['2. access to info, starting point', '3. access to info, starting point', '4. access to info', '5. access to info', 'Here are the responses with thematic tags:']\n",
            "Processed responses 20 to 25\n",
            "['', '1. access to info', '2. access to info, feedback & study support', '3. access to info, teaching', '4. access to info, teaching, feedback & study support']\n",
            "Processed responses 25 to 30\n",
            "['5. access to info, teaching, feedback & study support', 'Here are the responses with thematic tags:', '', '1. low cost, 24/7 availability', '2. teaching, access to info, feedback & study support']\n",
            "Processed responses 30 to 35\n",
            "['3. teaching, access to info, feedback & study support', '4. teaching, access to info, speeds up work', '5. teaching, access to info, feedback & study support, access to advanced topics', 'Here are the responses with thematic tags:', '']\n",
            "Processed responses 35 to 40\n",
            "['1. simplifying material, teaching', '2. access to info', '3. teaching', '4. access to info, teaching, feedback & study support', '5. teaching, feedback & study support']\n",
            "Processed responses 40 to 45\n",
            "['Here are the responses with thematic tags:', '', '1. teaching', '2. teaching', '3. teaching']\n",
            "Processed responses 45 to 50\n",
            "['4. access to info, teaching', '5. teaching', 'Here are the responses with thematic tags:', '', '1. They can help to simplify information in a pinch. - access to info, teaching']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPEN AI VERSION"
      ],
      "metadata": {
        "id": "p070Xy9ZDnIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "JfriHj5i-rdJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff23bee-583f-49d7-b628-93c026256241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.6.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/383.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "Successfully installed openai-1.51.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4-0613\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"\"\"example.\"\"\"\n",
        "    },\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "kNmtrVo6CG01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "ca176d41-d921-421e-c348-b73b2d1f074c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************Ig0w. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-9f26eefb22cd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4-0613\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    861\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    862\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    864\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         )\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    961\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************Ig0w. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    }
  ]
}
